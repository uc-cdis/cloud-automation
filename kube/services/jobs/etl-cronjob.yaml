apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: etl
spec:
  schedule: "@daily"
  successfulJobsHistoryLimit: 2
  failedJobsHistoryLimit: 2
  concurrencyPolicy: Forbid
  jobTemplate:
    spec:
      backoffLimit: 0
      template:
        metadata:
          labels:
            app: gen3job
        spec:
          affinity:
            nodeAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                preference:
                  matchExpressions:
                  - key: karpenter.sh/capacity-type
                    operator: In
                    values:
                    - on-demand
              - weight: 99
                preference:
                  matchExpressions:
                  - key: eks.amazonaws.com/capacityType
                    operator: In
                    values:
                    - ONDEMAND         
          volumes:
          - name: creds-volume
            secret:
              secretName: "peregrine-creds"
          - name: etl-mapping
            configMap:
              name: etl-mapping
          - name: fence-yaml
            configMap:
              name: fence
          restartPolicy: Never
          containers:
            - name: tube
              imagePullPolicy: Always
              ports:
              - containerPort: 80
              GEN3_TUBE_IMAGE
              env:
              - name: DICTIONARY_URL
                valueFrom:
                  configMapKeyRef:
                    name: manifest-global
                    key: dictionary_url
              - name: HADOOP_URL
                value: hdfs://spark-service:9000
              - name: ES_URL
                value: esproxy-service
              - name: ES_INDEX_NAME
                value: GEN3_TUBE_ES_INDEX_NAME|-null-|
              - name: HADOOP_HOST
                value: spark-service
              - name: HADOOP_CLIENT_OPTS
                value: -Xmx1g
              - name: SPARK_EXECUTOR_MEMORY
                value: 4g
              - name: SPARK_DRIVER_MEMORY
                value: 6g
              - name: slackWebHook
                valueFrom:
                    configMapKeyRef:
                      name: global
                      key: slack_webhook
                      optional: true
              - name: gen3Env
                valueFrom:
                    configMapKeyRef:
                      name: global
                      key: hostname
              volumeMounts:
              - name: "creds-volume"
                readOnly: true
                mountPath: "/gen3/tube/creds.json"
                subPath: creds.json
              - name: "etl-mapping"
                readOnly: true
                mountPath: "/gen3/tube/etlMapping.yaml"
                subPath: "etlMapping.yaml"
              - name: "fence-yaml"
                readOnly: true
                mountPath: "/gen3/tube/user.yaml"
                subPath: user.yaml
              resources:
                limits:
                  cpu: 1
                  memory: 10Gi
              command: ["/bin/bash"]
              args:
                - "-c"
                - |
                  python run_config.py && python run_etl.py
                  exitcode=$?
                  if [[ "${slackWebHook}" != 'None' ]]; then
                    if [[ $exitcode == 1 ]]; then
                      curl -X POST --data-urlencode "payload={\"text\": \"JOBFAIL: ETL job on ${gen3Env}\"}" "${slackWebHook}"
                    else
                      curl -X POST --data-urlencode "payload={\"text\": \"SUCCESS: ETL job on ${gen3Env}\"}" "${slackWebHook}"
                    fi
                  fi
                  echo "Exit code: $exitcode"
                  exit "$exitcode"

