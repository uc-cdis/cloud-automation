apiVersion: batch/v1
kind: Job
metadata:
  name: etl
spec:
  template:
    metadata:
      labels:
        app: gen3job
    spec:
      volumes:
      - name: creds-volume
        secret:
          secretName: "peregrine-creds"
      - name: etl-mapping
        configMap:
          name: etl-mapping
      containers:
      - name: tube
        imagePullPolicy: Always
        GEN3_TUBE_IMAGE
        ports:
        - containerPort: 80
        env:
        - name: DICTIONARY_URL
          valueFrom:
            configMapKeyRef:
              name: manifest-global
              key: dictionary_url
        - name: HADOOP_URL
          value: hdfs://spark-service:9000
        - name: ES_URL
          value: esproxy-service
        - name: HADOOP_HOST
          value: spark-service
        - name: HADOOP_CLIENT_OPTS
          value: -Xmx512m
        - name: SPARK_EXECUTOR_MEMORY
          value: 3g
        - name: SPARK_DRIVER_MEMORY
          value: 512m
        volumeMounts:
          - name: "creds-volume"
            readOnly: true
            mountPath: "/gen3/tube/creds.json"
            subPath: creds.json
          - name: "etl-mapping"
            readOnly: true
            mountPath: "/gen3/tube/etlMapping.yaml"
            subPath: "etlMapping.yaml"
        resources:
          limits:
            cpu: 1
            memory: 1Gi
        command: ["/bin/bash" ]
        args:
          - "-c"
          - |
            python run_config.py && python run_etl.py
            echo "All done - exit status $?"
      restartPolicy: Never
